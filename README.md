# LLM-Project

The first content `gpt2.py` and `inference.py`together is a test project that follows [Andrej Karpathy's GPT2 repreduction video](https://youtu.be/l8pRSuU81PU?si=2XtORh4Xk4NP2r4H) lesson with some changes.
It uses a small portion of [fineweb-edu](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu) dataset `600M tokens (100M validation)` with RTX 4090 Laptop GPU (16GB).<br>
The `Transformers` folder contains different implementation of GPT. A fine-tuning and a RAG example section will be added there as well.<br>
Main purpose for this project is to make a series of internal company sessions about LLMs and their implementation details.<br>
<br>
![screenshot](screenshot.png)

## Built With

- Python==3.10.14
- Pytorch==2.3.1+cu121

## Installation

**To set up and running these projects:**

1. Create a conda environment.<br>
2. Install the requirements.<br>

`conda create --name <ENV_NAME> python=3.10.14 --file requirements.txt`

## Authors

üë§ **Ey√ºp Sercan UYGUR**

[Srjnnnn(Twitter)](https://x.com/Srjnnnn)<br>
[eyupsercanuygur.com](https://www.eyupsercanuygur.com/)

## ü§ù Contributing

Contributions, issues and feature requests are welcome!

## Show your support

Give a ‚≠êÔ∏è if you like this project!

## Issues

For issues [check](https://github.com/Srjnnnn/LLM-Project/issues).

## üìù License

This project is [MIT](lic.url) licensed.
