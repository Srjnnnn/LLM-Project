{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sercan/anaconda3/envs/pytorch-environment/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "model_ckpt = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)\n",
    "text = \"time flies like an arrow\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2435, 17607,   588,   281, 15452]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoConfig\n",
    "import torch.nn.functional as F\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sercan/anaconda3/envs/pytorch-environment/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_ckpt)\n",
    "token_emb = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "token_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_embeds = token_emb(inputs.input_ids)\n",
    "inputs_embeds.size()  ## batch size, seq_len, hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    dim_k = query.size(-1)\n",
    "    scores = torch.bmm(query, key.transpose(1, 2)) / sqrt(dim_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    return weights.bmm(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(embed_dim, head_dim)\n",
    "        self.k = nn.Linear(embed_dim, head_dim)\n",
    "        self.v = nn.Linear(embed_dim, head_dim)\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        attn_outputs = scaled_dot_product_attention(\n",
    "            self.q(hidden_state), self.k(hidden_state), self.v(hidden_state))\n",
    "        return attn_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        embed_dim = config.hidden_size\n",
    "        num_heads = config.num_attention_heads\n",
    "        head_dim = embed_dim // num_heads\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        x = torch.cat([h(hidden_state) for h in self.heads], dim=-1)\n",
    "        x = self.output_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_attn = MultiHeadAttention(config)\n",
    "attn_output = multihead_attn(inputs_embeds)\n",
    "attn_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from bertviz import head_view\n",
    "\n",
    "model = AutoModel.from_pretrained(model_ckpt, output_attentions=True)\n",
    "viz_input = tokenizer(text, return_tensors='pt')\n",
    "print(viz_input)\n",
    "attention = model(**viz_input).attentions\n",
    "starting_point = (viz_input.input_ids == 2435).sum(dim=1)\n",
    "tokens = tokenizer.convert_ids_to_tokens(viz_input.input_ids[0])\n",
    "\n",
    "head_view(attention, tokens, starting_point, heads=[8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.41.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(config.hidden_size, 4*config.hidden_size)\n",
    "        self.linear_2 = nn.Linear(4*config.hidden_size, config.hidden_size)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_forward = FeedForward(config)\n",
    "ff_outputs = feed_forward(attn_output)\n",
    "ff_outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n",
    "        self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n",
    "        self.attention = MultiHeadAttention(config)\n",
    "        self.feed_forward = FeedForward(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply layer normalization and then copy input into query, key, value\n",
    "        hidden_state = self.layer_norm_1(x)\n",
    "        # Apply attention with a skip connection\n",
    "        x = x + self.attention(hidden_state)\n",
    "        # Apply feed-forward layer with a skip connection\n",
    "        x = x + self.feed_forward(self.layer_norm_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = nn.Embedding(config.vocab_size,\n",
    "                                             config.hidden_size)\n",
    "        self.position_embeddings = nn.Embedding(config.n_positions,\n",
    "                                                config.hidden_size)\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_epsilon)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # Create position IDs for input sequence\n",
    "        seq_length = input_ids.size(-1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)\n",
    "        # Create token and position embeddings\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        # Combine token and position embeddings\n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        ## embeddings = self.dropout(embeddings) ## I added this!!!!\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = Embeddings(config)\n",
    "embedding_layer(inputs.input_ids).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embeddings = Embeddings(config)\n",
    "        self.layers = nn.ModuleList([TransformerDecoderLayer(config)\n",
    "                                     for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = TransformerDecoder(config)\n",
    "decoder(inputs.input_ids).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerForTextGeneration(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.decoder = TransformerDecoder(config)\n",
    "        self.dropout = nn.Dropout(config.embd_pdrop)\n",
    "        self.ff_layer = nn.Linear(config.hidden_size, 50257)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)[:, 0, :]\n",
    "        x = self.dropout(x)\n",
    "        x = self.ff_layer(x)\n",
    "        x = F.softmax(x, dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = TransformerForTextGeneration(config)\n",
    "decoder_model_output = decoder_model(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 50\n",
    "maximum_value = torch.argmax(decoder_model_output)\n",
    "decoder_model_output[0][maximum_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50257])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_model_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2435, 17607,   588,   281, 15452]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = inputs.input_ids\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0895e-05, 1.3274e-05, 4.6472e-05,  ..., 1.6482e-05, 5.4983e-06,\n",
      "         1.2708e-05]])\n",
      "tensor([[17966,  7786, 13970, 31486, 29115, 17378, 35100, 37895, 38251, 45586,\n",
      "         22963, 46413, 28757, 43166, 35939,  2395,  3119,  8999, 16076, 38187,\n",
      "         23770, 38510, 42279, 29938, 30260, 40784, 34430, 33626, 13540, 21460,\n",
      "          8692, 14488, 20889, 37852, 43586, 18835, 32809, 43011, 35663,  9569,\n",
      "         24882, 35761, 38345, 21860, 20301, 26021, 47513, 45762,  2907, 43751]])\n",
      "tensor([[0.0004, 0.0004, 0.0004, 0.0004, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003,\n",
      "         0.0003, 0.0003, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002]])\n",
      "tensor([[35, 25, 27, 30, 18]])\n",
      "tensor([[18835, 40784, 33626,  8692, 16076]])\n",
      "tensor([[ 2435, 17607,   588,   281, 15452, 18835, 40784, 33626,  8692, 16076]])\n",
      "tensor([[7.3353e-06, 1.5564e-05, 3.9614e-05,  ..., 2.1478e-05, 8.7430e-06,\n",
      "         1.2745e-05]])\n",
      "tensor([[17378, 13970, 17966, 21860, 46413,  7786, 23770, 20889, 29115, 26414,\n",
      "         29938, 31486, 17657, 32809, 37895,  8999, 35761,  3119, 28051, 13206,\n",
      "         41264, 32466, 26555, 19133,  7998, 24304, 28757, 39107, 31259, 40784,\n",
      "         22963, 16076, 47513, 15298,  4012, 14992, 38251, 43728,  7166, 43011,\n",
      "         43618, 18835, 24063, 27792, 38187, 35252, 41818, 20623,  2395, 46300]])\n",
      "tensor([[0.0004, 0.0003, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002]])\n",
      "tensor([[ 9, 43, 18, 35, 10]])\n",
      "tensor([[26414, 27792, 28051, 14992, 29938]])\n",
      "tensor([[ 2435, 17607,   588,   281, 15452, 18835, 40784, 33626,  8692, 16076,\n",
      "         26414, 27792, 28051, 14992, 29938]])\n",
      "tensor([[1.0988e-05, 1.5082e-05, 3.5605e-05,  ..., 1.9457e-05, 8.6584e-06,\n",
      "         1.1972e-05]])\n",
      "tensor([[13970, 17378, 46413, 21860, 20889, 29115,  3119, 14992, 26555, 17966,\n",
      "         23770, 29938, 19133,  7998,  7786, 32809, 26414, 31486,  1083, 31259,\n",
      "         28757, 28051, 32466, 43166, 17657, 43728, 39107, 37895, 33626, 20623,\n",
      "         24882, 41818, 48409, 43751, 25562, 24304, 49797, 39123, 22963, 16076,\n",
      "         22112, 43011, 37923,  8167, 18835,  4012, 38251,  5772, 31315, 13206]])\n",
      "tensor([[0.0005, 0.0004, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001]])\n",
      "tensor([[10, 16,  0, 39,  7]])\n",
      "tensor([[23770, 26414, 13970, 16076, 14992]])\n",
      "tensor([[ 2435, 17607,   588,   281, 15452, 18835, 40784, 33626,  8692, 16076,\n",
      "         26414, 27792, 28051, 14992, 29938, 23770, 26414, 13970, 16076, 14992]])\n",
      "tensor([[1.0662e-05, 1.6262e-05, 3.0413e-05,  ..., 1.7549e-05, 8.2258e-06,\n",
      "         1.0498e-05]])\n",
      "tensor([[13970, 17378, 46413, 20889,  3119, 26555, 21860, 14992, 29115, 29938,\n",
      "         17966, 19133, 23770, 31486,  7998,  1083, 43728, 28051, 49797, 37923,\n",
      "         32809, 17657, 31315, 43166, 48409,  6375, 24882, 41818, 26414, 32466,\n",
      "         22963, 20623,  7786, 26021,  8582, 24304, 15174, 39955, 28757, 22112,\n",
      "         39107, 31259, 15008, 43751, 43636, 42279, 46280, 25238, 33626, 25562]])\n",
      "tensor([[0.0004, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001]])\n",
      "tensor([[ 3, 32,  2, 13, 33]])\n",
      "tensor([[20889,  7786, 46413, 31486, 26021]])\n",
      "tensor([[ 2435, 17607,   588,   281, 15452, 18835, 40784, 33626,  8692, 16076,\n",
      "         26414, 27792, 28051, 14992, 29938, 23770, 26414, 13970, 16076, 14992,\n",
      "         20889,  7786, 46413, 31486, 26021]])\n",
      "tensor([[1.1197e-05, 1.7311e-05, 3.7616e-05,  ..., 1.8650e-05, 8.8791e-06,\n",
      "         1.1478e-05]])\n",
      "tensor([[13970, 46413, 20889, 17378, 26555,  3119, 14992, 17966, 21860, 29938,\n",
      "         43728, 23770, 29115, 37923, 32809, 31486,  7998, 43166, 49797,  7786,\n",
      "         26414, 19133, 24304, 28051, 32466, 17657, 22112, 15174, 28757, 29671,\n",
      "         42279, 34483, 43636, 38510,  8999, 39123, 34764, 25238, 41818, 43011,\n",
      "         31315, 45682,  1083, 30497, 39107, 26021, 16076, 31259, 43751, 25562]])\n",
      "tensor([[0.0004, 0.0004, 0.0003, 0.0003, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001]])\n",
      "tensor([[29, 22,  4,  0, 19]])\n",
      "tensor([[29671, 24304, 26555, 13970,  7786]])\n",
      "tensor([[ 2435, 17607,   588,   281, 15452, 18835, 40784, 33626,  8692, 16076,\n",
      "         26414, 27792, 28051, 14992, 29938, 23770, 26414, 13970, 16076, 14992,\n",
      "         20889,  7786, 46413, 31486, 26021, 29671, 24304, 26555, 13970,  7786]])\n",
      "tensor([[1.1396e-05, 1.5892e-05, 4.0389e-05,  ..., 1.9712e-05, 7.9361e-06,\n",
      "         1.2056e-05]])\n",
      "tensor([[46413, 13970, 20889, 17378,  3119, 26555, 21860, 17966, 14992, 29938,\n",
      "         43728, 29115, 32809, 37923, 43166, 29671, 23770, 28757, 22112, 24304,\n",
      "          8999,  7998, 31486, 26414, 38510, 42279, 49797,  1083, 43636, 28051,\n",
      "         19133, 22963, 26021, 37895, 41818, 45682, 17489, 39107, 28135, 15174,\n",
      "          7786, 34483, 34764, 39123, 32466, 17657, 31259, 38982, 23416, 27627]])\n",
      "tensor([[0.0004, 0.0003, 0.0003, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001]])\n",
      "tensor([[ 7, 25, 43, 10,  8]])\n",
      "tensor([[17966, 42279, 39123, 43728, 14992]])\n",
      "tensor([[ 2435, 17607,   588,   281, 15452, 18835, 40784, 33626,  8692, 16076,\n",
      "         26414, 27792, 28051, 14992, 29938, 23770, 26414, 13970, 16076, 14992,\n",
      "         20889,  7786, 46413, 31486, 26021, 29671, 24304, 26555, 13970,  7786,\n",
      "         17966, 42279, 39123, 43728, 14992]])\n",
      "tensor([[1.1777e-05, 1.6549e-05, 4.0100e-05,  ..., 2.1420e-05, 8.1514e-06,\n",
      "         1.3564e-05]])\n",
      "tensor([[46413, 13970, 20889,  3119, 17378, 17966, 21860, 14992, 26555, 29115,\n",
      "         29938, 43728, 43166, 23770, 37923, 28757, 29671, 31486, 26414, 26021,\n",
      "          1083, 38510, 41818, 42279,  8999, 32809, 24304, 22963, 49797, 13715,\n",
      "         34483, 20623,  7998, 45682, 43636, 22112, 28051, 31259, 39107, 32466,\n",
      "         17489, 28135, 39955, 19133, 18835, 33626, 37895, 30497, 15174, 19537]])\n",
      "tensor([[0.0004, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001]])\n",
      "tensor([[45,  9, 22, 29,  1]])\n",
      "tensor([[33626, 29115, 41818, 13715, 13970]])\n",
      "tensor([[ 2435, 17607,   588,   281, 15452, 18835, 40784, 33626,  8692, 16076,\n",
      "         26414, 27792, 28051, 14992, 29938, 23770, 26414, 13970, 16076, 14992,\n",
      "         20889,  7786, 46413, 31486, 26021, 29671, 24304, 26555, 13970,  7786,\n",
      "         17966, 42279, 39123, 43728, 14992, 33626, 29115, 41818, 13715, 13970]])\n",
      "tensor([[1.2224e-05, 1.8483e-05, 3.7577e-05,  ..., 2.2019e-05, 7.3150e-06,\n",
      "         1.3356e-05]])\n",
      "tensor([[13970, 46413, 20889, 17378,  3119, 17966, 21860, 43728, 29938, 29115,\n",
      "         14992, 26555, 43166, 37923, 28757, 42279, 23770, 20623, 29671, 49797,\n",
      "         26414, 45682,  8999, 31259, 32809, 24304, 26021, 39107, 31486, 38510,\n",
      "          1083, 34483, 41818, 13715, 28135, 24882, 22963, 17531, 43636,  7998,\n",
      "         39955, 26662, 18835, 28051, 39123, 32466, 22112, 30497, 19133, 17750]])\n",
      "tensor([[0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001]])\n",
      "tensor([[49,  8,  4, 44,  3]])\n",
      "tensor([[17750, 29938,  3119, 39123, 17378]])\n",
      "tensor([[ 2435, 17607,   588,   281, 15452, 18835, 40784, 33626,  8692, 16076,\n",
      "         26414, 27792, 28051, 14992, 29938, 23770, 26414, 13970, 16076, 14992,\n",
      "         20889,  7786, 46413, 31486, 26021, 29671, 24304, 26555, 13970,  7786,\n",
      "         17966, 42279, 39123, 43728, 14992, 33626, 29115, 41818, 13715, 13970,\n",
      "         17750, 29938,  3119, 39123, 17378]])\n",
      "tensor([[1.1537e-05, 1.6898e-05, 3.6660e-05,  ..., 2.2059e-05, 7.3310e-06,\n",
      "         1.3420e-05]])\n",
      "tensor([[46413, 13970, 20889, 17378,  3119, 17966, 21860, 29938, 43728, 14992,\n",
      "         29115, 26555, 37923, 43166, 26414, 23770, 29671, 28757, 45682,  8999,\n",
      "         20623, 49797, 39107, 38510, 31486, 42279,  1083, 24304, 30497, 34483,\n",
      "         39955, 28051, 26021, 22963, 16076, 32809, 31259, 26662, 17531, 43011,\n",
      "         41818, 39123, 34764, 32466, 37895, 18835, 24882, 19133, 43636, 22112]])\n",
      "tensor([[0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "         0.0002, 0.0002, 0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0001]])\n",
      "tensor([[30, 42,  1,  0,  9]])\n",
      "tensor([[39955, 34764, 13970, 46413, 14992]])\n",
      "tensor([[ 2435, 17607,   588,   281, 15452, 18835, 40784, 33626,  8692, 16076,\n",
      "         26414, 27792, 28051, 14992, 29938, 23770, 26414, 13970, 16076, 14992,\n",
      "         20889,  7786, 46413, 31486, 26021, 29671, 24304, 26555, 13970,  7786,\n",
      "         17966, 42279, 39123, 43728, 14992, 33626, 29115, 41818, 13715, 13970,\n",
      "         17750, 29938,  3119, 39123, 17378, 39955, 34764, 13970, 46413, 14992]])\n",
      "tensor([[ 2435, 17607,   588,   281, 15452, 18835, 40784, 33626,  8692, 16076,\n",
      "         26414, 27792, 28051, 14992, 29938, 23770, 26414, 13970, 16076, 14992,\n",
      "         20889,  7786, 46413, 31486, 26021, 29671, 24304, 26555, 13970,  7786,\n",
      "         17966, 42279, 39123, 43728, 14992, 33626, 29115, 41818, 13715, 13970,\n",
      "         17750, 29938,  3119, 39123, 17378, 39955, 34764, 13970, 46413, 14992]])\n",
      "> time flies like an arrowunalSup masteredbase athlete Andrewsajaiczrying neoc orgasm Andrews beside athleterying sue sharp staples Gast splitting OEM detectives triggering beside sharpclosure Jingearned Lyonsrying mastered valuationWeaponsFixed besideinition neoc propertyearned Vel fortunately WARRANT beside staplesrying\n"
     ]
    }
   ],
   "source": [
    "while input_ids.size(1) < max_length:\n",
    "    ## forward the model to get the logits\n",
    "    decoder_model.eval()\n",
    "    with torch.no_grad():    \n",
    "        probs = decoder_model(input_ids) ## (B, T, vocab_size)\n",
    "        ## We'll do the top k sampling here (HF's default 50 for pipeline)\n",
    "        print(probs)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1, largest=True) ## If you want some fun change the 1 to some other number and you'll have different answers!!!\n",
    "        ## Select a token from top-k probabilities\n",
    "        print(topk_indices)\n",
    "        print(topk_probs)\n",
    "        ix = torch.multinomial(topk_probs, 5, generator=torch.cuda.manual_seed(42), replacement=False) ## (B, 1)\n",
    "        print(ix)\n",
    "        ## gather the corresponding indices\n",
    "        xcol = torch.gather(topk_indices, -1, ix) ## (B, 1)\n",
    "        print(xcol)\n",
    "        ## append to the sequence to get the full generated sentences\n",
    "        input_ids = torch.cat((input_ids, xcol), dim=1)\n",
    "        print(input_ids)\n",
    "\n",
    "# Print the predicted token IDs\n",
    "print(input_ids)\n",
    "\n",
    "## decode and print the generated text\n",
    "tokens = input_ids[0, :max_length].detach().to('cpu').tolist()\n",
    "decoded = tokenizer.decode(tokens)\n",
    "print(\">\", decoded)\n",
    "input_ids = torch.tensor( [[2435, 17607,   588,   281, 15452]], dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2435, 17607,   588,   281, 15452]], dtype=torch.int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor( [[2435, 17607,   588,   281, 15452]], dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
